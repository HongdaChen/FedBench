{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca998065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pickle\n",
    "import tarfile\n",
    "from math import sqrt\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, EMNIST, CIFAR10,CIFAR100\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from resnetcifar import ResNet18_cifar10, ResNet50_cifar10\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bba6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(dataset, datadir, logdir, partition, n_parties, beta=0.4):\n",
    "    if dataset == 'cifar10':\n",
    "        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)\n",
    "    elif dataset == 'cifar100':\n",
    "        X_train, y_train, X_test, y_test = load_cifar100_data(datadir)\n",
    "    elif dataset == 'tinyimagenet':\n",
    "        X_train, y_train, X_test, y_test = load_tinyimagenet_data(datadir)\n",
    "\n",
    "    n_train = y_train.shape[0]\n",
    "\n",
    "    if partition == \"homo\" or partition == \"iid\":\n",
    "        idxs = np.random.permutation(n_train)\n",
    "        batch_idxs = np.array_split(idxs, n_parties)\n",
    "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
    "\n",
    "\n",
    "    elif partition == \"noniid-labeldir\" or partition == \"noniid\":\n",
    "        min_size = 0\n",
    "        min_require_size = 10\n",
    "        K = 10\n",
    "        if dataset == 'cifar100':\n",
    "            K = 100\n",
    "        elif dataset == 'tinyimagenet':\n",
    "            K = 200\n",
    "            # min_require_size = 100\n",
    "\n",
    "        N = y_train.shape[0]\n",
    "        net_dataidx_map = {}\n",
    "\n",
    "        while min_size < min_require_size:\n",
    "            idx_batch = [[] for _ in range(n_parties)]\n",
    "            for k in range(K):\n",
    "                idx_k = np.where(y_train == k)[0]\n",
    "                np.random.shuffle(idx_k)\n",
    "                proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
    "                proportions = np.array([p * (len(idx_j) < N / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n",
    "                proportions = proportions / proportions.sum()\n",
    "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "                min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "                # if K == 2 and n_parties <= 10:\n",
    "                #     if np.min(proportions) < 200:\n",
    "                #         min_size = 0\n",
    "                #         break\n",
    "\n",
    "        for j in range(n_parties):\n",
    "            np.random.shuffle(idx_batch[j])\n",
    "            net_dataidx_map[j] = idx_batch[j]\n",
    "\n",
    "    traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)\n",
    "    return (X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts)\n",
    "\n",
    "def load_cifar10_data(datadir):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    cifar10_train_ds = CIFAR10_truncated(datadir, train=True, download=True, transform=transform)\n",
    "    cifar10_test_ds = CIFAR10_truncated(datadir, train=False, download=True, transform=transform)\n",
    "\n",
    "    X_train, y_train = cifar10_train_ds.data, cifar10_train_ds.target\n",
    "    X_test, y_test = cifar10_test_ds.data, cifar10_test_ds.target\n",
    "\n",
    "    # y_train = y_train.numpy()\n",
    "    # y_test = y_test.numpy()\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "def record_net_data_stats(y_train, net_dataidx_map, logdir):\n",
    "    net_cls_counts = {}\n",
    "\n",
    "    for net_i, dataidx in net_dataidx_map.items():\n",
    "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
    "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
    "        net_cls_counts[net_i] = tmp\n",
    "\n",
    "    data_list=[]\n",
    "    for net_id, data in net_cls_counts.items():\n",
    "        n_total=0\n",
    "        for class_id, n_data in data.items():\n",
    "            n_total += n_data\n",
    "        data_list.append(n_total)\n",
    "    print('mean:', np.mean(data_list))\n",
    "    print('std:', np.std(data_list))\n",
    "    logger.info('Data statistics: %s' % str(net_cls_counts))\n",
    "\n",
    "    return net_cls_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ca2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1., net_id=None, total=0):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.net_id = net_id\n",
    "        self.num = int(sqrt(total))\n",
    "        if self.num * self.num < total:\n",
    "            self.num = self.num + 1\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if self.net_id is None:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            tmp = torch.randn(tensor.size())\n",
    "            filt = torch.zeros(tensor.size())\n",
    "            size = int(28 / self.num)\n",
    "            row = int(self.net_id / size)\n",
    "            col = self.net_id % size\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    filt[:,row*size+i,col*size+j] = 1\n",
    "            tmp = tmp * filt\n",
    "            return tensor + tmp * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f818a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, datadir, train_bs, test_bs, dataidxs=None, noise_level=0, net_id=None, total=0):\n",
    "    if dataset in ('mnist', 'femnist', 'fmnist', 'cifar10', 'svhn', 'generated', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
    "        if dataset == 'mnist':\n",
    "            dl_obj = MNIST_truncated\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "        elif dataset == 'femnist':\n",
    "            dl_obj = FEMNIST\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "        elif dataset == 'fmnist':\n",
    "            dl_obj = FashionMNIST_truncated\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "        elif dataset == 'svhn':\n",
    "            dl_obj = SVHN_custom\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "\n",
    "        elif dataset == 'cifar10':\n",
    "            dl_obj = CIFAR10_truncated\n",
    "\n",
    "            transform_train = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: F.pad(\n",
    "                    Variable(x.unsqueeze(0), requires_grad=False),\n",
    "                    (4, 4, 4, 4), mode='reflect').data.squeeze()),\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomCrop(32),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)\n",
    "            ])\n",
    "            # data prep for test set\n",
    "            transform_test = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
    "\n",
    "        else:\n",
    "            dl_obj = Generated\n",
    "            transform_train = None\n",
    "            transform_test = None\n",
    "\n",
    "\n",
    "        train_ds = dl_obj(datadir, dataidxs=dataidxs, train=True, transform=transform_train, download=True)\n",
    "        test_ds = dl_obj(datadir, train=False, transform=transform_test, download=True)\n",
    "\n",
    "        train_dl = data.DataLoader(dataset=train_ds, batch_size=train_bs, shuffle=True, drop_last=False)\n",
    "        test_dl = data.DataLoader(dataset=test_ds, batch_size=test_bs, shuffle=False, drop_last=False)\n",
    "\n",
    "    return train_dl, test_dl, train_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3f235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_truncated(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
    "\n",
    "        self.root = root\n",
    "        self.dataidxs = dataidxs\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.download = download\n",
    "\n",
    "        self.data, self.target = self.__build_truncated_dataset__()\n",
    "\n",
    "    def __build_truncated_dataset__(self):\n",
    "\n",
    "        cifar_dataobj = CIFAR10(self.root, self.train, self.transform, self.target_transform, self.download)\n",
    "\n",
    "        if torchvision.__version__ == '0.2.1':\n",
    "            if self.train:\n",
    "                data, target = cifar_dataobj.train_data, np.array(cifar_dataobj.train_labels)\n",
    "            else:\n",
    "                data, target = cifar_dataobj.test_data, np.array(cifar_dataobj.test_labels)\n",
    "        else:\n",
    "            data = cifar_dataobj.data\n",
    "            target = np.array(cifar_dataobj.targets)\n",
    "\n",
    "        if self.dataidxs is not None:\n",
    "            data = data[self.dataidxs]\n",
    "            target = target[self.dataidxs]\n",
    "\n",
    "        return data, target\n",
    "\n",
    "    def truncate_channel(self, index):\n",
    "        for i in range(index.shape[0]):\n",
    "            gs_index = index[i]\n",
    "            self.data[gs_index, :, :, 1] = 0.0\n",
    "            self.data[gs_index, :, :, 2] = 0.0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.target[index]\n",
    "        # img = Image.fromarray(img)\n",
    "        # print(\"cifar10 img:\", img)\n",
    "        # print(\"cifar10 target:\", target)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34e083",
   "metadata": {},
   "source": [
    "## generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526a4f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data statistics: {0: {0: 953, 1: 142, 2: 141, 3: 75, 4: 695, 5: 819, 7: 2482}, 1: {0: 16, 1: 43, 2: 902, 3: 1650, 4: 86, 5: 182, 7: 693, 8: 110, 9: 6}, 2: {0: 9, 1: 8, 2: 290, 3: 769, 4: 841, 5: 283, 6: 119, 7: 1044, 8: 1014, 9: 58}, 3: {0: 395, 1: 1200, 2: 48, 3: 68, 4: 896, 5: 681, 6: 90, 7: 17, 8: 1351, 9: 301}, 4: {0: 504, 1: 2917, 2: 570, 3: 721, 4: 121, 5: 356}, 5: {0: 1262, 1: 71, 2: 325, 3: 119, 4: 1560, 5: 14, 6: 1, 7: 85, 8: 366}, 6: {0: 9, 1: 273, 2: 1657, 3: 40, 4: 1, 5: 130, 6: 1911, 7: 21, 8: 1160}, 7: {0: 722, 1: 3, 2: 281, 3: 738, 4: 22, 5: 974, 6: 624, 7: 1, 8: 82, 9: 878}, 8: {0: 1127, 1: 153, 2: 680, 3: 500, 4: 698, 5: 1139, 6: 92, 7: 23, 8: 1, 9: 3665}, 9: {0: 3, 1: 190, 2: 106, 3: 320, 4: 80, 5: 422, 6: 2163, 7: 634, 8: 916, 9: 92}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 5000.0\n",
      "std: 1165.398901664147\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "alpha = 0.5\n",
    "all_clients = 10\n",
    "X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts = partition_data(\n",
    "\"cifar10\", \"../data\", \"../data\", \"noniid\", all_clients, beta=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f72931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dl_local, test_dl_local, train_ds, test_ds = get_dataloader(\"cifar10\", \n",
    "                                                                      '../data', 64, 32,\n",
    "                                                                      dataidxs=net_dataidx_map[0],\n",
    "                                                                  noise_level=0.1,net_id=0, total=1)\n",
    "# train_ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9fda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3bf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dl_local))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b544d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(next(iter(train_dl_local))[0][0]).resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5ad3ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=256, drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9af8b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import shutil\n",
    "# data_ = train_ds.data\n",
    "# labels_=list(train_ds.target)\n",
    "\n",
    "# for i in range(10):\n",
    "#     if i not in Counter(train_ds.target).keys():\n",
    "#         for j in range(10):\n",
    "#             data_=np.concatenate((data_,np.zeros_like(data_[0]).reshape((1,32, 32, 3))))\n",
    "#             labels_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "37112f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4479, 3072)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e0fae787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put the data that after partition into disk from memory, so CAREFULLY DO IT TO NOT OVERWRITE THE EXISTING DATA\n",
    "for client in range(10):\n",
    "    train_dl_local, test_dl_local, train_ds, test_ds = get_dataloader(\"cifar10\", \n",
    "                                                                      '../data', 64, 32,\n",
    "                                                                      dataidxs=net_dataidx_map[client])\n",
    "    data_ = train_ds.data\n",
    "    labels_=list(train_ds.target)\n",
    "\n",
    "    for i in range(10):\n",
    "        if i not in Counter(train_ds.target).keys():\n",
    "            for j in range(10):\n",
    "                data_=np.concatenate((data_,np.zeros_like(data_[0]).reshape((1,32, 32, 3))))\n",
    "                labels_.append(i)\n",
    "            \n",
    "    num = data_.shape[0]\n",
    "    step = num//5\n",
    "    data_ = data_.reshape(num,-1)\n",
    "#     labels_=list(train_ds.target)\n",
    "    os.makedirs(\"cifar-10-batches-py\",exist_ok=True)\n",
    "    for i in range(5):\n",
    "        dic = {}\n",
    "        dic['data']=data_[step*i:step*(i+1)]\n",
    "        dic['labels']=labels_[step*i:step*(i+1)]\n",
    "        with open(\"cifar-10-batches-py/data_batch_\"+str(i+1),\"wb\") as f:\n",
    "            pickle.dump(dic,f)\n",
    "\n",
    "    ## verify\n",
    "    data = []\n",
    "    targets = []\n",
    "    downloaded_list = [\n",
    "        \"cifar-10-batches-py/data_batch_1\",\n",
    "        \"cifar-10-batches-py/data_batch_2\",\n",
    "        \"cifar-10-batches-py/data_batch_3\",\n",
    "        \"cifar-10-batches-py/data_batch_4\",\n",
    "        \"cifar-10-batches-py/data_batch_5\"\n",
    "    ]\n",
    "    # now load the picked numpy arrays\n",
    "    for file_name in downloaded_list:\n",
    "        file_path = file_name\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            entry = pickle.load(f, encoding=\"latin1\")\n",
    "            data.append(entry[\"data\"])\n",
    "            if \"labels\" in entry:\n",
    "                targets.extend(entry[\"labels\"])\n",
    "            else:\n",
    "                targets.extend(entry[\"fine_labels\"])\n",
    "\n",
    "    data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
    "    data = data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "    # data.shape\n",
    "    #  should like this: (5305, 32, 32, 3)\n",
    "\n",
    "    # compress file to tar.gz\n",
    "    def Converter(path, tar):\n",
    "        with tarfile.open(tar, \"w:gz\") as t:\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for file in files:\n",
    "                    t.add(file)\n",
    "        \n",
    "    Converter(\"cifar-10-batches-py\", \"cifar-10-python.tar.gz\")\n",
    "    # move to new dir\n",
    "    ne_path = \"data/alpha-\"+str(alpha)+\"/partition_client_\"+str(client+1)\n",
    "    os.makedirs(ne_path) # ,exist_ok=True)\n",
    "    shutil.move(\"cifar-10-python.tar.gz\",ne_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef46da94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aikedaer/Desktop/FedMOON/ipynb'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162a2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=traindata_cls_counts\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2, 5, sharex='col', sharey='row',figsize=(25,10))\n",
    "for i in range(10):\n",
    "    if i==0:\n",
    "        ax[i//5,i%5].set_ylabel(\"Number of corresponding label\")\n",
    "    elif i>5:\n",
    "        ax[i//5,i%5].set_xlabel(\"Class_label\")\n",
    "    elif i==5:\n",
    "        ax[i//5,i%5].set_ylabel(\"Number of corresponding label\")\n",
    "        ax[i//5,i%5].set_xlabel(\"Class_label\")\n",
    "        \n",
    "    ax[i//5,i%5].set_xlim(-1,10)\n",
    "    ax[i//5,i%5].bar(list(x[i].keys()),list(x[i].values()),width = 1)\n",
    "    ax[i//5,i%5].set_title(\"client-{0}\".format(i))\n",
    "    for m,n in zip(list(x[i].keys()),list(x[i].values())):\n",
    "        ax[i//5,i%5].text(m+0.05,n+0.05,'%d' %n, ha='center',va='bottom')\n",
    "# plt.title(\"partition-\"+str(alpha)) not work\n",
    "plt.savefig(\"data/alpha-\"+str(alpha)+\"/partition.png\",dpi=330)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aeff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab61d20",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef0da9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional, Tuple\n",
    "import hashlib\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class MYCIFAR10(torch.utils.data.Dataset):\n",
    "    base_folder = \"cifar-10-batches-py\"\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n",
    "    train_list = [\n",
    "        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n",
    "        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n",
    "        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n",
    "        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n",
    "        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n",
    "    ]\n",
    "    meta = {\n",
    "        \"filename\": \"batches.meta\",\n",
    "        \"key\": \"label_names\",\n",
    "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        #         super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.root = root\n",
    "        self.train = train  # training set or test set\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.downlod = download\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                entry = pickle.load(f, encoding=\"latin1\")\n",
    "                self.data.append(entry[\"data\"])\n",
    "                if \"labels\" in entry:\n",
    "                    self.targets.extend(entry[\"labels\"])\n",
    "                else:\n",
    "                    self.targets.extend(entry[\"fine_labels\"])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "    def _load_meta(self) -> None:\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n",
    "        with open(path, \"rb\") as infile:\n",
    "            data = pickle.load(infile, encoding=\"latin1\")\n",
    "            self.classes = data[self.meta[\"key\"]]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "#     def extract_file(self):\n",
    "#         # open file\n",
    "#         file = tarfile.open('gfg.tar.gz')\n",
    "\n",
    "#         # extracting file\n",
    "#         file.extractall('./Destination_FolderName')\n",
    "\n",
    "#         file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f94d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                              transforms.ToPILImage(),\n",
    "                              transforms.RandomRotation(50,expand=True),  \n",
    "                              transforms.ToTensor()\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1d9632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5335, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "cifar_dataobj = MYCIFAR10(\"data/alpha-0.5/partition_client_1\", True, transform)\n",
    "cifar_dataobj.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16efbab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_dataobj.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "06bb02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = [0.4914, 0.4822, 0.4465]\n",
    "# # std = [0.2023, 0.1994, 0.2010]\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "# cifar_dataobj = CIFAR10(\"../data\", True, transform,download=True)\n",
    "# cifar_dataobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "92dbe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_obj = MYCIFAR10(\"data/alpha-0.5/partition_client_1\",True,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a4e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_obj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e4ec7a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0\n",
      "1\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for i in Counter(cifar10_obj.targets).keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0e3ab5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_obj.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8dd35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = []\n",
    "targets = []\n",
    "downloaded_list = [\n",
    "    \"/home/aikedaer/Desktop/cifar-10-batches-py/data_batch_1\",\n",
    "    \"/home/aikedaer/Desktop/cifar-10-batches-py/data_batch_2\",\n",
    "    \"/home/aikedaer/Desktop/cifar-10-batches-py/data_batch_3\",\n",
    "    \"/home/aikedaer/Desktop/cifar-10-batches-py/data_batch_4\",\n",
    "    \"/home/aikedaer/Desktop/cifar-10-batches-py/data_batch_5\"\n",
    "]\n",
    "# now load the picked numpy arrays\n",
    "for file_name in downloaded_list:\n",
    "    file_path = file_name\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        entry = pickle.load(f, encoding=\"latin1\")\n",
    "        data.append(entry[\"data\"])\n",
    "        if \"labels\" in entry:\n",
    "            targets.extend(entry[\"labels\"])\n",
    "        else:\n",
    "            targets.extend(entry[\"fine_labels\"])\n",
    "\n",
    "data = np.vstack(data).reshape(-1, 3, 32, 32)\n",
    "data = data.transpose((0, 2, 3, 1))  # convert to HWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b744f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.transpose((0,3,1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "017a840d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_label', 'labels', 'data', 'filenames'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a610152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry['filenames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06aa3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1df0e7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93cf4b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d60d8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"partition\",\"wb\") as f:\n",
    "    h = pickle.dump(data.reshape(-1),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40bf7aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  62,  63, ..., 163, 163, 161], dtype=uint8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"partition\", \"rb\") as f:\n",
    "    ed = pickle.load(f, encoding=\"latin1\")\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dba0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].reshape(-1).reshape((32,32,3))==data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11ce4a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 252, 253, ..., 173, 231, 248],\n",
       "       [127, 126, 127, ..., 102, 108, 112],\n",
       "       [116,  64,  19, ...,   7,   6,   5],\n",
       "       ...,\n",
       "       [ 35,  40,  42, ...,  77,  66,  50],\n",
       "       [189, 186, 185, ..., 169, 171, 171],\n",
       "       [229, 236, 234, ..., 173, 162, 161]], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621cf27",
   "metadata": {},
   "source": [
    "\n",
    "https://datamahadev.com/performing-image-augmentation-using-pytorch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fac33e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform1 = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=mean, std=std)])\n",
    "# root_folder is the string containing address of the root image data directory \n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Lambda(lambda x: F.pad(\n",
    "#         Variable(x.unsqueeze(0), requires_grad=False),\n",
    "#         (4, 4, 4, 4), mode='reflect').data.squeeze()),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ColorJitter(brightness=0.1),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root = \"../data\", transform=transform_train)\n",
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02dc0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(32),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "transform_aug(dataset[0][0]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef4aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.randn_like(dataset[0][0])*(1/10)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "111e9b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53286812",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "for idx, (x,y) in enumerate(testloader):\n",
    "    display(transforms.ToPILImage()(x[0]).resize((256,256)))\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b4640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "827bbe3d",
   "metadata": {},
   "source": [
    "Performing Image Augmentation using Pytorch\n",
    "\n",
    "by Aman Sharma · September 7, 2020\n",
    "6+\t\n",
    "A Detailed Guide on How to Use Image Augmentation in PyTorch to Give Your Models a Data Boost.\n",
    "\n",
    "In the last few years, there have been some major breakthroughs and developments in the field of Deep Learning. The constant research and rapid developments have made Deep Learning an industry-standard in the field of AI and the main topic of discussion in almost every AI and Data Science conventions, overthrowing its parent and predecessor— traditional Machine Learning. \n",
    "\n",
    "When it comes to Computer Vision, that strictly deals with video and image data, and problems like object detection, body pose detection, image segmentation, etc., Deep Learning has proved out to be a much more reliable option as compared to the traditional Machine Learning.\n",
    "\n",
    "The reason behind this is that Deep Learning specializes is tackling high dimensionality problems. While machine learning works perfectly fine when you only have a few hundred features to train your model on, the performance starts to deteriorate as the dimensionality of your data increases. With the evolution of Data Science and Big Data over the years, the complexity of the problems and the type of data the Data Scientists have to work with has increased a lot. \n",
    "\n",
    "To give you an idea of this massive increase in the scale of data, we will consider an example here. Let’s say that you are working on an image dataset, where you have to deal with 3000×4000 px RGB images.\n",
    "\n",
    "Considering each pixel data to be a feature, every single data instance (i.e., the images) will have (3000 x 4000 x 3) = 36,000,000 features. Yes, the number of features that the model will have to train on is in millions, which is, frankly speaking, not feasible for almost any traditional machine learning algorithm to handle.\n",
    "\n",
    "Deep Learning, on the other hand, performs exceptionally well when we have to deal with high dimensional data, like the images in the example we discussed above. This makes Deep Learning the ideal choice for Computer Vision problems. \n",
    "\n",
    "This ability to deal with high dimensional data makes Deep Learning seem so powerful, right? And now that GPUs don’t cost an arm and a leg (and that you can access free, high-speed GPUs for free via services like Google Colab), it might seem like there’s no need for traditional Machine Learning at all! \n",
    "\n",
    "However, there’s a catch here. Generally, it is observed that the performance of a Deep Learning model is directly proportional to the size of the dataset, i.e., the total number of data instances within a dataset.\n",
    "\n",
    "Upon a glance at the graph given above, you will observe a rather strange pattern in it. You will see that when the size of the dataset is small, Machine Learning tends to perform slightly better. However, as the size of the dataset that the model is to be trained on increases, Deep Learning models really start to outperform their Machine Learning counterparts by a huge margin.\n",
    "\n",
    "The reason? Deep Learning model architectures, in general, have millions of parameters to train in order to effectively adapt to certain patterns within the data. To facilitate this extensive training task, a very large amount of data is required. If there isn’t enough data for the model to train, the model’s inference performance will take a huge hit, and you might not get the results that you expected.\n",
    "\n",
    "Therefore, if you are working on a Computer Vision problem, say an image segmentation problem, then in order to get a good performance out of a Deep Learning model, you obviously need large amounts of image data. Now one solution to this can be a collection of more images for training your model. But the downside of data collection is that it can be a very expensive task, both economically as well as technologically. \n",
    "\n",
    "A more economically feasible option would a technique known as Image Augmentation. If you are just getting started in Deep Learning, this might be an entirely new term for you. In that case, you have ended up in the right place. In this article, we will understand what Image Augmentation is, as well as have a look at how to apply image augmentation to training data in Python using PyTorch.\n",
    "\n",
    "So, let’s get started.\n",
    "Image Augmentation\n",
    "\n",
    "Image Augmentation can be defined as the process by which we can generate new images by creating randomized variations in the existing image data. The technique can be used to increase the size of your dataset by creating additional data instances that can be used to train your model on. For an image classifications model, this simply translates to better performance.\n",
    "\n",
    "I think the definition will become clearer once you see an example. In the example given below, we have the original image of an SUV on a street. \n",
    "\n",
    "In the first augmented image, by zooming in and increasing the brightness, we got a new image. The second augmented image was generated by tweaking the hue and temperature of the original image. In the third augmented image, the original image was vertically flipped. Thus, just by tweaking the color and the alignment of the images, we were able to create 3 more data instances that a model can train on. \n",
    "\n",
    "For human eyes, all these images in the example given above might look alike. But for a Deep Learning model that deals with the images as individual pixels (with values ranging from 0-255) spanning across the 3 color channels (RGB), all these images are different, since the individual pixel values of these images are different. Thus, image augmentation allows us to generate new image data for training our deep learning model without having to go extra lengths to collect the data manually. \n",
    "\n",
    "One more advantage that the image augmentation technique provides for Deep Learning is that by creating randomization in the image data, it significantly reduces the chances of the model overfitting on the training data. This allows the model to generalize better, and hence, improves the inference accuracy of the model.\n",
    "Image Augmentation Using PyTorch\n",
    "\n",
    "Now that we know what the image augmentation technique is used for, let us have a look at how you can implement a variety of image augmentations in PyTorch.\n",
    "\n",
    "For this tutorial, first, we will understand the use and the effect of different image augmentation methods individually on a single image. Once we are done with that, we will see how to perform image augmentations in a Deep Learning project for a real-world dataset.\n",
    "\n",
    "Let us begin by importing all the necessary PyData modules and PyTorch.\n",
    "\n",
    "Now, before we start performing the transformations, let us have a look at our original image.\n",
    "\n",
    "Now, let us have a look at some of the most used image augmentation techniques in PyTorch and the purpose they are used for.\n",
    "\n",
    "    `CenterCrop` – The CenterCrop image augmentation is used to crop the input image at the center. The size of the crop is determined by the help of the ‘size’ attribute. A single integer value as the size argument performs a square cropping on the image of dimension size x size. To set a custom size, the value of the size attribute should be a tuple size = (width, height).\n",
    "\n",
    "Here’s how to implement CenterCrop in PyTorch:\n",
    "\n",
    "    `ColorJitter`– ColorJitter augmentation technique is used to randomly change the brightness, contrast, saturation, and hue of the image. Unlike the CenterCrop image augmentation that we saw earlier, ColorJitter doesn’t have a fixed behavior. Rather, it results in a random color augmentation each time. \n",
    "\n",
    "Here’s how to implement ColorJitter in PyTorch:\n",
    "\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "color_jitter = torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)\n",
    "img = color_jitter(img)\n",
    "plt.imshow(img)\n",
    "\n",
    "view raw\n",
    "color_jitter.py hosted with ❤ by GitHub\n",
    "\n",
    "    `Grayscale` – The Grayscale image augmentation is used to convert a multi-channeled (RGB, CYAN, etc.) image into a single-channeled (gray-scaled) or triple-channeled (r==g==b) image.\n",
    "\n",
    "Here’s how to implement Grayscale in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "gray = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "img = gray(img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "view raw\n",
    "gray.py hosted with ❤ by GitHub\n",
    "\n",
    "    `Pad`– The Pad image transform is used to pad the given image on all sides. The thickness of the padding is determined by the ‘padding’ argument. \n",
    "\n",
    "Here’s how to implement Pad in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "pad = torchvision.transforms.Pad(50, fill=0, padding_mode='constant')\n",
    "img = pad(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "pad.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomCrop`– The RandomCrop image augmentation acts in a way similar to that as the CenterCrop. The only difference is that it crops the original image at any random location rather than from just the center. Again, the size of the crop is determined by the ‘size’ attribute.\n",
    "\n",
    "Here’s how to implement RandomCrop in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "random_crop = torchvision.transforms.RandomCrop((200, 300), fill=0, padding_mode='constant')\n",
    "img = random_crop(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "random_crop.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomHorizontalFlip` – The RandomHorizontalFlip image augmentation horizontally flips the image. The probability of the flipping operation can be controlled using the ‘p’ attribute, its value ranging from 0 <= p <=1. \n",
    "\n",
    "Here’s how to implement RandomHorizontalFlip in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "horizontal_flip = torchvision.transforms.RandomHorizontalFlip(p=1)\n",
    "img = horizontal_flip(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "horizontal_flip.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomVerticalFlip` – Just like the horizontal flip augmentation that we saw earlier, RandomVerticalFlip also flips the image. The only difference is the flipping occurs across the x-axis, i.e., in simple words, in the vertical direction. The probability of the flipping operation can be controlled using the ‘p’ attribute, its value ranging from 0 <= p <=1. \n",
    "\n",
    "Here’s how to implement RandomVerticalFlip in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "vertical_flip = torchvision.transforms.RandomVerticalFlip(p=1)\n",
    "img = vertical_flip(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "vertical_flip.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomPerspective` – The RandomPerspective image augmentation is used to randomly distort the image along with a given perspective. The probability of the flipping operation can be controlled using the ‘p’ attribute, its value ranging from 0 <= p <=1.; and the scale of the distortion can be controlled using the ‘distortion_scale’ attribute, its value also ranging between 0-1.\n",
    "\n",
    "Here’s how to implement RandomPerspective in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "random_persp = torchvision.transforms.RandomPerspective(distortion_scale=0.5, p=1, interpolation=3, fill=0)\n",
    "img = random_persp(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "random_perspective.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomRotation` – The RandomRotation randomly rotates the image. The degree of rotation of the image is determined using the ‘degree’ attribute. \n",
    "\n",
    "Here’s how to implement RandomRotation in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "random_rotation = torchvision.transforms.RandomRotation(degrees = 45)\n",
    "img = random_rotation(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "random_rotate.py hosted with ❤ by GitHub\n",
    "\n",
    "    `RandomErasing` – The RandomErasing image augmentation technique randomly selects a rectangular region in the original image and erases all the pixels in the region. The probability or the erase operation can be controlled using the ‘p’ attribute, its value ranging from 0 <= p <=1.\n",
    "\n",
    "Here’s how to implement RandomErasing in PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "tensor = torchvision.transforms.ToTensor()\n",
    "random_erase = torchvision.transforms.RandomErasing(p=1)\n",
    "\n",
    "img = tensor(img)\n",
    "img = random_erase(img)\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "view raw\n",
    "random_erase.py hosted with ❤ by GitHub\n",
    "\n",
    "Now that we have seen some of the most used image augmentation techniques in PyTorch, let us have a look at how to apply these in a real-world project. Generally, the augmentations/transforms are applied in a sequence, all at once. For this, we have to use torchvision.transforms.Compose() method. The augmentations that are to be performed on the images are passes to the compose method as an argument.\n",
    "\n",
    "Let us see how to implement this using PyTorch:\n",
    "img = Image.open('/content/2_city_car_.jpg')\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((300,400)),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20)\n",
    "])\n",
    "\n",
    "img = transforms(img)\n",
    "plt.imshow(img)\n",
    "view raw\n",
    "compose.py hosted with ❤ by GitHub\n",
    "\n",
    "Up until now, we saw how to apply the transformations/augmentations on a single image. But in real-world problems, the datasets may have thousands of images. \n",
    "\n",
    "Unlike the Pandas DataFrames that we see in many traditional machine learning problems, it is generally not possible to store all the images in the memory (RAM) at once in the form of DataFrames. Therefore, PyTorch handles these images via the various Dataset classes available in PyTorch.In order to apply the transforms on an entire dataset, all you need to do is pass the torchvision.transforms.Compose method object (or an individual image augmentation method object, if you want) as the value to the ‘transform’ attribute. There are several Dataset classes in PyTorch, but as an example, we will see how to apply the image augmentation to an ImageFolder dataset.\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((300,400)),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20)\n",
    "])\n",
    "\n",
    "root_folder is the string containing address of the root image data directory \n",
    "`dataset = torchvision.datasets.ImageFolder(root = root_folder, transform=transforms)`\n",
    "view raw\n",
    "dataset.py hosted with ❤ by GitHub\n",
    "\n",
    "With this, we come to an end of our tutorial part where we learned why image augmentation is necessary for Deep Learning and how to apply different image augmentations in PyTorch. By using multiple combinations of augmentations on different batches of data and retraining your model on this augmented and original data again and again over several epochs (training cycles), you can overcome the barrier that has a small image dataset poses against your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fd08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
